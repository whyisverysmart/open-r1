model: # Model specific parameters
  base_params:
    model_args: "pretrained=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B,dtype=bfloat16,context_length=131072,tp_size=1,mem_fraction_static=0.7,attention_backend=torch_native,random_seed=5678" # Model args that you would pass in the command line
  generation: # Generation specific parameters
    temperature: 0.6
    top_p: 0.95
    max_new_tokens: 32768